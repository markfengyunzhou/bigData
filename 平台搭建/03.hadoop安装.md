## hadoop 集群部署

* 版本
```
2.9.0
```
* 下载解压
```
tar -xvf hadoop-2.9.0.tar.gz
```

* 配置各种home
```
HADOOP_HOME
YARN_CONF_DIR
HADOOP_CONF_DIR
```

* 配置hadoop-env.sh

```
export JAVA_HOME=${JAVA_HOME}
#export HADOOP_HEAPSIZE=2000
#export HADOOP_NAMENODE_INIT_HEAPSIZE=2000
export HADOOP_LOG_DIR=xxx
```
* 免秘钥打通
```
ssh-keygen -t rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys
```

* 伪分布式
```
core-site.xml
<property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
</property>
```
```
hdfs-site.xml
<property>
        <name>dfs.replication</name>
        <value>1</value>
</property>
```
## 完成分布式
* 配置hdfs-site.xml
```
<property>
    <name>dfs.data.dir</name>
    <value>xxx, xxx</value>
</property>

<property>
    <name>dfs.name.dir</name>
    <value>xxx</value>
</property>

<property>
        <name>dfs.replication</name>
        <value>2</value>
</property>
<property>
        <name>dfs.permissions</name>
        <value>false</value>
</property>
```

* 配置core-site.xml
```
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://xxx:9000</value>
    </property>

    <property>
        <name>fs.trash.interval</name>
        <value>1440</value>
    </property>
</configuration>
```

* 配置mapred-site.xml
```
<property>
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
</property>
```

* 配置yarn-site.xml
```
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>xxx</value>
  </property>

  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>

  <property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
  </property>

  <property>
    <name>yarn.nodemanager.remote-app-log-dir</name>
    <value>hdfs://xx:9000/user/hpe/yarn-logs/</value>
  </property>

  <property>
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>2592000</value>
  </property>

  <property>
    <name>yarn.log.server.url</name>
    <value>http://xx:19888/jobhistory/logs</value>
  </property>

  <property>
          <name>yarn.nodemanager.resource.memory-mb</name>
          <value>4096</value> <!-- 4G -->
  </property>
  <property>
          <name>yarn.scheduler.minimum-allocation-mb</name>
          <value>2048</value>
  </property>
  <property>
          <name>yarn.scheduler.maximum-allocation-mb</name>
          <value>2048</value>
  </property>
  <property>
          <name>yarn.app.mapreduce.am.resource.mb</name>
          <value>2048</value>
  </property>
  <property>
          <name>yarn.nodemanager.resource.cpu-vcores</name>
          <value>4</value>
  </property>

  <property>
          <name>yarn.scheduler.maximum-allocation-vcores</name>
          <value>16</value>
  </property>
```
* 启动historyserver
```
mr-jobhistory-daemon.sh start historyserver
```

* 启动httphdfs
```
vi httpfs-env.sh
export HTTPFS_HTTP_PORT=14000

vi hdfs-site.xml
<property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
</property>

vi core-site.xml
   <property>
     <name>hadoop.proxyuser.hpe.hosts</name>
     <value>*</value>
   </property>
   <property>
     <name>hadoop.proxyuser.hpe.groups</name>
     <value>*</value>
   </property>
```
```
httpfs.sh start
```

* trouble shooting
```
防火墙
ntpdate
```
