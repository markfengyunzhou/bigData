## logstash install

* 版本
```
6.5.3
https://www.elastic.co/downloads/logstash
```

* test.conf
```
input {
     file {
         type => "NameNode"
         path => "/home/hpe/data4Hadoop/logData/*.log"
         discover_interval => 5
         start_position => "beginning"
     }
}
output {
    if [type] == "NameNode" {
        elasticsearch {
             index => "flow-%{+YYYY.MM.dd}"
             hosts => ["m3:9200", "m4:9200", "m5:9200"]
        }
    }
}
```

* start agent
```
bin/logstash -f config/test.conf
```

* 安装multiline插件(如果需要) 
```
bin/logstash-plugin install logstash-filter-multiline
```

* hdfs log
```
input {
     file {
         type => "NameNode"
         path => "/home/hpe/data4Hadoop/logData/hadoop-hpe-namenode*.log"
         discover_interval => 5
         start_position => "beginning"
     }
}

input {
     file {
         type => "DataNode"
         path => "/home/hpe/data4Hadoop/logData/hadoop-hpe-datanode*.log"
         discover_interval => 5
         start_position => "beginning"
     }
}

input {
     file {
         type => "JournalNode"
         path => "/home/hpe/data4Hadoop/logData/hadoop-hpe-journalnode*.log"
         discover_interval => 5
         start_position => "beginning"
     }
}

filter {
    if [type] == "NameNode" or [type] == "DataNode" or [type] == "JournalNode"
      {
        # hadoop log4j log start with ISO8601 date format, following
        # lines not start with date should be merged into single event
        multiline{
            pattern => "^%{TIMESTAMP_ISO8601}"
            what => "previous"
            negate => true
        }
        # grok CANNOT hadnle string with \n, replace \n first
        mutate {
            gsub => ['message', "\n", " @LINE_BREAK@ "]
        }
        # match hadoop log4j format
        grok {
            match => [message, "%{DATA:ts} %{WORD:level} %{JAVACLASS:class}: %{GREEDYDATA:log_msg}" ]
        }

        # use log date as timestamp
        date {
            match => [ "ts", "yyyy-MM-dd HH:mm:ss,SSS"]
            #timezone =>  "Asia/Shanghai"
        }
        
        mutate {
            gsub => ['log_msg', "@LINE_BREAK@", "\n"]
            # The new line here is the only why to put a new line ...
            gsub => ["log_msg", "\\n", ""]
            gsub => ["log_msg", "\\$", ""]
        }
        
        if "_grokparsefailure" in [tags] {
            # grok not match, leave message field for debug
            mutate {
                remove_field => [ "tags" ]
            }
        } else {
            # grok match, remove extra field
            mutate {
                remove_field => [ "tags", "message", "ts" ]
            }
        }
    }
}

output {
    if [type] == "NameNode" or [type] == "DataNode" or [type] == "JournalNode" 
    {
        elasticsearch {
             index => "hdfs-%{+YYYY.MM}"
             hosts => ["m3:9200", "m4:9200", "m5:9200"]
        }
    }
}

```
